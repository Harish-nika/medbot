{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract and store embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from unstructured.partition.pdf import partition_pdf  # Use partition_pdf for PDF processing\n",
    "from unstructured.chunking.title import chunk_by_title  # Import chunking strategy (by title or by similarity)\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Set directory to save embeddings and text chunks\n",
    "EMBEDDING_DIR = \"/home/harish/Agentic_AI/embeddings\"\n",
    "TEXT_CHUNKS_DIR = \"/home/harish/Agentic_AI/text_chunks\"  # Directory for text chunks\n",
    "os.makedirs(EMBEDDING_DIR, exist_ok=True)\n",
    "os.makedirs(TEXT_CHUNKS_DIR, exist_ok=True)\n",
    "\n",
    "# Load SBERT model\n",
    "def load_embedding_model():\n",
    "    return SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load the model before running the code\n",
    "embedding_model = load_embedding_model()\n",
    "\n",
    "# Function to extract text from PDFs using partition_pdf\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    # Partition the PDF document using partition_pdf (with \"fast\" strategy for extractable text)\n",
    "    elements = partition_pdf(pdf_file, strategy=\"fast\")  # Adjust strategy if needed (\"hi_res\", \"ocr_only\")\n",
    "    \n",
    "    # Extract the text content from the elements\n",
    "    document_text = [element.text for element in elements if hasattr(element, 'text')]\n",
    "    return document_text\n",
    "\n",
    "# Function to chunk text based on title or similarity\n",
    "def chunk_text(elements, strategy=\"by_title\"):\n",
    "    # Choose the chunking strategy (by title or by similarity)\n",
    "    if strategy == \"by_title\":\n",
    "        from unstructured.chunking.title import chunk_by_title\n",
    "        chunks = chunk_by_title(elements)\n",
    "    elif strategy == \"by_similarity\":\n",
    "        from unstructured.chunking.basic import chunk_elements\n",
    "        chunks = chunk_elements(elements, strategy=\"by_similarity\", similarity_threshold=0.7)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown chunking strategy. Choose 'by_title' or 'by_similarity'.\")\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Function to generate embeddings using SBERT (batch processing)\n",
    "def get_embeddings_batch(texts):\n",
    "    embeddings = embedding_model.encode(texts, show_progress_bar=True, batch_size=16)  # Batch processing\n",
    "    return embeddings\n",
    "\n",
    "# Function to process the PDF files\n",
    "def process_pdf(file_path, chunking_strategy=\"by_title\"):\n",
    "    # Read the PDF using partition_pdf\n",
    "    elements = partition_pdf(file_path, strategy=\"fast\")  # Use partition_pdf to extract text\n",
    "    \n",
    "    # Chunk the extracted elements by title or similarity\n",
    "    chunks = chunk_text(elements, strategy=chunking_strategy)\n",
    "    \n",
    "    # If chunks are too large, further split them using RecursiveCharacterTextSplitter\n",
    "    all_chunks = []\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    for chunk in chunks:\n",
    "        sub_chunks = text_splitter.split_text(chunk.text)\n",
    "        all_chunks.extend(sub_chunks)\n",
    "    \n",
    "    # Batch processing of embeddings\n",
    "    start_time = time.time()\n",
    "    embeddings = get_embeddings_batch(all_chunks)\n",
    "    print(f\"Embedding generation took {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    embeddings = np.array(embeddings, dtype=np.float32)\n",
    "    \n",
    "    # Save embeddings to .npy file\n",
    "    save_path = os.path.join(EMBEDDING_DIR, f\"{os.path.basename(file_path)}.npy\")\n",
    "    np.save(save_path, embeddings)\n",
    "    print(f\"Embeddings saved for {os.path.basename(file_path)}\")\n",
    "    \n",
    "    # Save text chunks to .pkl file\n",
    "    text_chunks_path = os.path.join(TEXT_CHUNKS_DIR, f\"{os.path.basename(file_path)}_chunks.pkl\")\n",
    "    with open(text_chunks_path, 'wb') as f:\n",
    "        pickle.dump(all_chunks, f)\n",
    "    print(f\"Text chunks saved for {os.path.basename(file_path)}\")\n",
    "\n",
    "# Process PDF files (adjust the paths to the PDFs)\n",
    "pdf_files = [\"/home/harish/Agentic_AI/books/Current_Essentials_of_Medicine.pdf\"]  # Example PDF file paths\n",
    "for pdf_file in pdf_files:\n",
    "    process_pdf(pdf_file, chunking_strategy=\"by_title\")  # Use either chunking_strategy'by_title' or 'by_similarity'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#search and enhancement via llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index created with 2668 entries.\n",
      "Response from ChatGroq: content=\"Here is the information you requested for Amphetamines, Ecstasy, and Cocaine:\\n\\n**Essentials of Diagnosis**\\n\\n* Substance intoxication and/or withdrawal (e.g., amphetamines, ecstasy, cocaine) can present with a wide range of symptoms, including:\\n\\t+ Psychiatric symptoms: agitation, anxiety, paranoia, hallucinations, and mood disturbances\\n\\t+ Neurological symptoms: tremors, muscle rigidity, and seizures\\n\\t+ Cardiovascular symptoms: tachycardia, hypertension, and cardiac arrhythmias\\n\\t+ Gastrointestinal symptoms: nausea, vomiting, and abdominal pain\\n\\t+ Respiratory symptoms: tachypnea and respiratory depression\\n\\n**Differential Diagnosis**\\n\\n* For amphetamines:\\n\\t+ Substance intoxication and/or withdrawal (e.g., cocaine, ecstasy)\\n\\t+ Medication use (e.g., methylphenidate, thyroxine)\\n\\t+ Endocrinopathies (e.g., hyperthyroidism, Cushing's syndrome)\\n\\t+ Central nervous system neoplasm\\n\\t+ Complex partial seizures\\n\\t+ Personality disorders (e.g., borderline, narcissistic)\\n* For ecstasy:\\n\\t+ Substance intoxication and/or withdrawal (e.g., amphetamines, cocaine)\\n\\t+ Medication use (e.g., selective serotonin reuptake inhibitors, antihypertensives)\\n\\t+ Underlying medical condition (e.g., chronic illness, hormone deficiencies)\\n\\t+ Neurologic disease (e.g., cerebrovascular accident, postictal state, meningitis)\\n\\t+ Other psychotropic drug intoxication; neuroleptic malignant syndrome\\n* For cocaine:\\n\\t+ Substance intoxication and/or withdrawal (e.g., amphetamines, ecstasy)\\n\\t+ Medication use (e.g., steroids, thyroxine, methylphenidate)\\n\\t+ Endocrinopathies (e.g., hyperthyroidism, Cushing's syndrome)\\n\\t+ Central nervous system neoplasm\\n\\t+ Complex partial seizures\\n\\t+ Personality disorders (e.g., borderline, narcissistic)\\n\\n**Treatment**\\n\\n* Maintenance of a highly structured environment and clear, consistent interactions with the patient\\n* Individual or group therapy (e.g., cognitive-behavioral, interpersonal)\\n* Antipsychotic medications may be required transiently in times of acute agitation or psychosis\\n* Benzodiazepines or other sedatives may be used to manage agitation, anxiety, or insomnia\\n* Alpha-2 agonists or other medications may be used to manage hypertension or tachycardia\\n\\nPlease note that this information is general and not specific to individual cases. It is essential to consult with a healthcare professional for accurate diagnosis and treatment.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 548, 'prompt_tokens': 505, 'total_tokens': 1053, 'completion_time': 0.456666667, 'prompt_time': 0.079823131, 'queue_time': 0.03613907799999999, 'total_time': 0.536489798}, 'model_name': 'Llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None} id='run-cdfd5c21-0137-4e09-9d26-5b0ffb126a90-0' usage_metadata={'input_tokens': 505, 'output_tokens': 548, 'total_tokens': 1053}\n",
      "Response type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "Answer from ChatGroq: Here is the information you requested for Amphetamines, Ecstasy, and Cocaine:\n",
      "\n",
      "**Essentials of Diagnosis**\n",
      "\n",
      "* Substance intoxication and/or withdrawal (e.g., amphetamines, ecstasy, cocaine) can present with a wide range of symptoms, including:\n",
      "\t+ Psychiatric symptoms: agitation, anxiety, paranoia, hallucinations, and mood disturbances\n",
      "\t+ Neurological symptoms: tremors, muscle rigidity, and seizures\n",
      "\t+ Cardiovascular symptoms: tachycardia, hypertension, and cardiac arrhythmias\n",
      "\t+ Gastrointestinal symptoms: nausea, vomiting, and abdominal pain\n",
      "\t+ Respiratory symptoms: tachypnea and respiratory depression\n",
      "\n",
      "**Differential Diagnosis**\n",
      "\n",
      "* For amphetamines:\n",
      "\t+ Substance intoxication and/or withdrawal (e.g., cocaine, ecstasy)\n",
      "\t+ Medication use (e.g., methylphenidate, thyroxine)\n",
      "\t+ Endocrinopathies (e.g., hyperthyroidism, Cushing's syndrome)\n",
      "\t+ Central nervous system neoplasm\n",
      "\t+ Complex partial seizures\n",
      "\t+ Personality disorders (e.g., borderline, narcissistic)\n",
      "* For ecstasy:\n",
      "\t+ Substance intoxication and/or withdrawal (e.g., amphetamines, cocaine)\n",
      "\t+ Medication use (e.g., selective serotonin reuptake inhibitors, antihypertensives)\n",
      "\t+ Underlying medical condition (e.g., chronic illness, hormone deficiencies)\n",
      "\t+ Neurologic disease (e.g., cerebrovascular accident, postictal state, meningitis)\n",
      "\t+ Other psychotropic drug intoxication; neuroleptic malignant syndrome\n",
      "* For cocaine:\n",
      "\t+ Substance intoxication and/or withdrawal (e.g., amphetamines, ecstasy)\n",
      "\t+ Medication use (e.g., steroids, thyroxine, methylphenidate)\n",
      "\t+ Endocrinopathies (e.g., hyperthyroidism, Cushing's syndrome)\n",
      "\t+ Central nervous system neoplasm\n",
      "\t+ Complex partial seizures\n",
      "\t+ Personality disorders (e.g., borderline, narcissistic)\n",
      "\n",
      "**Treatment**\n",
      "\n",
      "* Maintenance of a highly structured environment and clear, consistent interactions with the patient\n",
      "* Individual or group therapy (e.g., cognitive-behavioral, interpersonal)\n",
      "* Antipsychotic medications may be required transiently in times of acute agitation or psychosis\n",
      "* Benzodiazepines or other sedatives may be used to manage agitation, anxiety, or insomnia\n",
      "* Alpha-2 agonists or other medications may be used to manage hypertension or tachycardia\n",
      "\n",
      "Please note that this information is general and not specific to individual cases. It is essential to consult with a healthcare professional for accurate diagnosis and treatment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Directory for embeddings and text chunks\n",
    "EMBEDDING_DIR = \"/home/harish/Agentic_AI/embedding_chunk_bytitle\"\n",
    "TEXT_CHUNKS_DIR = \"/home/harish/Agentic_AI/chunked_be_title\"\n",
    "\n",
    "# Load environment variables (API keys, etc.)\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Initialize ChatGroq LLM\n",
    "llm = ChatGroq(groq_api_key=GROQ_API_KEY, model_name=\"Llama3-8b-8192\", temperature=0)\n",
    "\n",
    "def load_embeddings():\n",
    "    \"\"\"\n",
    "    Loads stored embeddings (.npy) and text chunks from their respective directories.\n",
    "    \"\"\"\n",
    "    embeddings_list = []\n",
    "    text_chunks = []\n",
    "\n",
    "    files_found = [f for f in os.listdir(EMBEDDING_DIR) if f.endswith(\".npy\")]\n",
    "    if not files_found:\n",
    "        raise FileNotFoundError(\"⚠️ No `.npy` embedding files found!\")\n",
    "\n",
    "    for file in files_found:\n",
    "        file_path = os.path.join(EMBEDDING_DIR, file)\n",
    "        text_file = file.replace(\".npy\", \"_chunks.pkl\")\n",
    "        text_path = os.path.join(TEXT_CHUNKS_DIR, text_file)\n",
    "\n",
    "        try:\n",
    "            embed = np.load(file_path)\n",
    "            embeddings_list.append(embed)\n",
    "\n",
    "            with open(text_path, \"rb\") as f:\n",
    "                texts = pickle.load(f)\n",
    "                text_chunks.extend(texts)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not embeddings_list:\n",
    "        raise ValueError(\"❌ No valid embeddings found.\")\n",
    "\n",
    "    embeddings = np.vstack(embeddings_list)  # Stack embeddings\n",
    "    return embeddings, text_chunks\n",
    "\n",
    "def create_faiss_index(embeddings):\n",
    "    \"\"\"\n",
    "    Creates a FAISS index for fast similarity search.\n",
    "    \"\"\"\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])  # L2 distance metric for FAISS\n",
    "    index.add(embeddings)  # Add embeddings to FAISS\n",
    "    return index\n",
    "\n",
    "# Load embeddings and create FAISS index\n",
    "try:\n",
    "    embeddings, text_chunks = load_embeddings()\n",
    "    faiss_index = create_faiss_index(embeddings)\n",
    "    print(\"✅ FAISS index created with\", embeddings.shape[0], \"entries.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize your embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # Use the model that fits your use case\n",
    "\n",
    "def search_faiss_index(query, faiss_index, embeddings, text_chunks, k=5):\n",
    "    \"\"\"\n",
    "    Perform a search on the FAISS index for the most similar embeddings to the query.\n",
    "    \"\"\"\n",
    "    # Convert query to embedding using the same model\n",
    "    query_embedding = embedding_model.encode([query])  # Make sure embedding_model is defined\n",
    "\n",
    "    # Perform the FAISS search\n",
    "    distances, indices = faiss_index.search(np.array(query_embedding).astype(np.float32), k)\n",
    "    \n",
    "    # Retrieve the most similar text chunks\n",
    "    top_k_chunks = [text_chunks[i] for i in indices[0]]\n",
    "    \n",
    "    return top_k_chunks, distances[0]\n",
    "\n",
    "\n",
    "# def create_chatgroq_prompt(top_k_chunks, query):\n",
    "#     \"\"\"\n",
    "#     Creates a formatted prompt for ChatGroq using retrieved chunks.\n",
    "#     \"\"\"\n",
    "#     context = \"\\n\".join(top_k_chunks)\n",
    "#     prompt = ChatPromptTemplate.from_template(\n",
    "#         \"\"\"\n",
    "#         Answer the following question based on the provided context:\n",
    "#         <context>\n",
    "#         {context}\n",
    "#         </context>\n",
    "#         Question: {input}\n",
    "#         \"\"\"\n",
    "#     )\n",
    "    \n",
    "#     formatted_prompt = prompt.format(context=context, input=query)\n",
    "#     return formatted_prompt\n",
    "def create_chatgroq_prompt(top_k_chunks, query):\n",
    "    \"\"\"\n",
    "    Creates a formatted prompt for ChatGroq using retrieved chunks and mandatory instructions.\n",
    "    \"\"\"\n",
    "    # Join the top K chunks into a single context string\n",
    "    context = \"\\n\".join(top_k_chunks)\n",
    "    \n",
    "    # Construct the prompt with mandatory instructions for MedBot\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Instructions:\n",
    "        - Provide accurate, clear, and medically relevant information based on the provided context.\n",
    "        - If the information is unclear or missing, indicate that clearly.\n",
    "        - Avoid giving personal medical advice; the response should be informative and factual.\n",
    "        - Ensure medical terminology is explained where necessary, using simple language when possible.\n",
    "        - Always clarify when a response is based on general information and not professional medical advice.\n",
    "        \n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {input}\n",
    "\n",
    "        Please provide your response below:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Format the prompt with the provided context and input query\n",
    "    formatted_prompt = prompt.format(context=context, input=query)\n",
    "    return formatted_prompt\n",
    "\n",
    "\n",
    "\n",
    "def query_chatgroq_with_context(query, faiss_index, embeddings, text_chunks, top_k=5):\n",
    "    \"\"\"\n",
    "    Query ChatGroq with the enhanced context retrieved from FAISS search.\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve the relevant chunks from FAISS\n",
    "    top_k_chunks, distances = search_faiss_index(query, faiss_index, embeddings, text_chunks, k=top_k)\n",
    "\n",
    "    # Step 2: Prepare the prompt for ChatGroq\n",
    "    formatted_prompt = create_chatgroq_prompt(top_k_chunks, query)\n",
    "\n",
    "    # Step 3: Query ChatGroq with the enhanced prompt\n",
    "    response = llm.invoke(formatted_prompt)  # Use the correct method to invoke\n",
    "\n",
    "    # Debugging: Print the response and its type\n",
    "    print(f\"Response from ChatGroq: {response}\")\n",
    "    print(f\"Response type: {type(response)}\")  # Check the type of response\n",
    "\n",
    "    # Assuming the answer is stored in the 'content' attribute\n",
    "    return response.content  # Or adjust if a different attribute is used\n",
    "\n",
    "# Example query\n",
    "query = \"give me information like( Essentials of Diagnosis, Differential Diagnosis, Treatment) Amphetamines, Ecstasy, Cocaine\"\n",
    "\n",
    "# Query ChatGroq with relevant context from FAISS\n",
    "answer = query_chatgroq_with_context(query, faiss_index, embeddings, text_chunks, top_k=5)\n",
    "\n",
    "print(f\"Answer from ChatGroq: {answer}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medbotenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
